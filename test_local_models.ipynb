{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer_climate_related = AutoTokenizer.from_pretrained(\"climatebert/distilroberta-base-climate-detector\")\n",
    "model_climate_related = AutoModelForSequenceClassification.from_pretrained(\"climatebert/distilroberta-base-climate-detector\")\n",
    "\n",
    "tokenizer_ron = AutoTokenizer.from_pretrained(\"climatebert/distilroberta-base-climate-sentiment\")\n",
    "model_ron = AutoModelForSequenceClassification.from_pretrained(\"climatebert/distilroberta-base-climate-sentiment\")\n",
    "\n",
    "tokenizer_tcfd = AutoTokenizer.from_pretrained(\"climatebert/distilroberta-base-climate-tcfd\")\n",
    "model_tcfd = AutoModelForSequenceClassification.from_pretrained(\"climatebert/distilroberta-base-climate-tcfd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer_climate_related(\"Paris Agreement\", return_tensors=\"pt\")\n",
    "inputs2 = tokenizer_ron(\"Paris Agreement\", return_tensors=\"pt\")\n",
    "inputs3 = tokenizer_tcfd(\"Paris Agreement\", return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_tcfd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3996, -0.0702,  0.5137, -0.0117]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = model_climate_related.forward(**inputs)\n",
    "# b = model_climate_related(**inputs)\n",
    "# a.logits\n",
    "# tokenizer.decode([a.logits.argmax()])\n",
    "\n",
    "output1 = model_climate_related(**inputs)\n",
    "output2 = model_ron(**inputs2)\n",
    "output3 = model_tcfd(**inputs3)\n",
    "\n",
    "output1.logits\n",
    "output2.logits\n",
    "output3.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate Related:\n",
      "Probabilities: tensor([[0.0122, 0.9878]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(0.0122, grad_fn=<SelectBackward0>)\n",
      "Predicted Class: 1\n",
      "{'no': 0.012168703600764275, 'yes': 0.9878312945365906}\n",
      "RON:\n",
      "Probabilities: tensor([[0.3221, 0.4492, 0.2287]], grad_fn=<SoftmaxBackward0>)\n",
      "Predicted Class: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/aidacolovic/Documents/projects/uni-master/project2-digitalization/project/test_local_models.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aidacolovic/Documents/projects/uni-master/project2-digitalization/project/test_local_models.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m response \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aidacolovic/Documents/projects/uni-master/project2-digitalization/project/test_local_models.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, label \u001b[39min\u001b[39;00m model_ron\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mid2label\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aidacolovic/Documents/projects/uni-master/project2-digitalization/project/test_local_models.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     response[label] \u001b[39m=\u001b[39m probabilities1[\u001b[39m0\u001b[39;49m][key]\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aidacolovic/Documents/projects/uni-master/project2-digitalization/project/test_local_models.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# print(key)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aidacolovic/Documents/projects/uni-master/project2-digitalization/project/test_local_models.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "probabilities1 = F.softmax(output1.logits, dim=1)\n",
    "probabilities2 = F.softmax(output2.logits, dim=1)\n",
    "probabilities3 = F.softmax(output3.logits, dim=1)\n",
    "\n",
    "# Get the predicted class (index with the maximum probability)\n",
    "predicted_class1 = torch.argmax(probabilities1, dim=1).item()\n",
    "predicted_class2 = torch.argmax(probabilities2, dim=1).item()\n",
    "predicted_class3 = torch.argmax(probabilities3, dim=1).item()\n",
    "\n",
    "# class labels: \"no\": 0, \"yes\": 1\n",
    "print(\"Climate Related:\")\n",
    "print(\"Probabilities:\", probabilities1)\n",
    "print(probabilities1[0][0])\n",
    "print(\"Predicted Class:\", predicted_class1)\n",
    "\n",
    "response = {}\n",
    "for key, label in model_climate_related.config.id2label.items():\n",
    "    response[label] = probabilities1[0][key].item()\n",
    "    # print(key)\n",
    "print(response)\n",
    "\n",
    "# class labels: \"neutral\": 1, \"opportunity\": 0, \"risk\": 2\n",
    "print(\"RON:\")\n",
    "print(\"Probabilities:\", probabilities2)\n",
    "print(\"Predicted Class:\", predicted_class2)\n",
    "\n",
    "response = {}\n",
    "for key, label in model_ron.config.id2label.items():\n",
    "    response[label] = probabilities2[0][key].item()\n",
    "    # print(key)\n",
    "print(response)\n",
    "\n",
    "# class labels: \"governance\": 0, \"risk\": 1, \"strategy\": 2, \"metrics\": 3\n",
    "print(\"TCFD:\")\n",
    "print(\"Probabilities:\", probabilities3)\n",
    "print(\"Predicted Class:\", predicted_class3)\n",
    "\n",
    "response = {}\n",
    "for key, label in model_tcfd.config.id2label.items():\n",
    "    response[label] = probabilities3[0][key].item()\n",
    "    # print(key)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "governance\n",
      "risk\n",
      "strategy\n",
      "metrics\n"
     ]
    }
   ],
   "source": [
    "for key, label in model_tcfd.config.id2label.items():\n",
    "        print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration: RobertaConfig {\n",
      "  \"_name_or_path\": \"climatebert/distilroberta-base-climate-tcfd\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"governance\",\n",
      "    \"1\": \"risk\",\n",
      "    \"2\": \"strategy\",\n",
      "    \"3\": \"metrics\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"governance\": 0,\n",
      "    \"metrics\": 3,\n",
      "    \"risk\": 1,\n",
      "    \"strategy\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50500\n",
      "}\n",
      "\n",
      "Number of Classes: 4\n"
     ]
    }
   ],
   "source": [
    "# Print the model's configuration, which includes the number of classes\n",
    "print(\"Model Configuration:\", model_tcfd.config)\n",
    "\n",
    "num_classes = model_tcfd.config.num_labels\n",
    "print(\"Number of Classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'governance'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tcfd.config.id2label[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_climate_related.batch_decode(a.logits.argmax(dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0478,  0.0886, -0.0098,  ..., -0.0544, -0.0672, -0.0039],\n",
       "         [-0.0712,  0.0150, -0.1299,  ...,  0.0638,  0.0296, -0.0860],\n",
       "         [ 0.0906,  0.1437,  0.0828,  ...,  0.0509, -0.0320, -0.0490],\n",
       "         ...,\n",
       "         [ 0.0853,  0.2155,  0.0849,  ..., -0.1150,  0.0330, -0.0790],\n",
       "         [ 0.1679,  0.1288,  0.0065,  ...,  0.0367, -0.0631,  0.0276],\n",
       "         [-0.0436,  0.0892, -0.0389,  ..., -0.0957, -0.0744, -0.0284]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_call_one',\n",
       " '_cls_token',\n",
       " '_compile_jinja_template',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_set_processor_class',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " '_upload_modified_files',\n",
       " 'add_prefix_space',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'default_chat_template',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'max_model_input_sizes',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_init_configuration',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer_climate_related)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
